Figure 3.2: State-value function (V) for uniform random policy. (V = âˆ‘ action_prob * q_value)
+------------+-----------+-----------+-----------+-----------+
|  3.31311   |  8.79335  |  4.43144  |  5.32599  |  1.49562  |
+------------+-----------+-----------+-----------+-----------+
|  1.52567   |  2.99631  |  2.25393  |  1.91118  |  0.550869 |
+------------+-----------+-----------+-----------+-----------+
|  0.0548918 |  0.742147 |  0.676931 |  0.361836 | -0.399599 |
+------------+-----------+-----------+-----------+-----------+
| -0.969506  | -0.431488 | -0.351013 | -0.581873 | -1.17943  |
+------------+-----------+-----------+-----------+-----------+
| -1.85359   | -1.3412   | -1.22535  | -1.41913  | -1.97146  |
+------------+-----------+-----------+-----------+-----------+
Optimal policy:
+-------+----------------------+-------+----------------------+-------+
| ['e'] | ['n', 'w', 's', 'e'] | ['w'] | ['n', 'w', 's', 'e'] | ['w'] |
+-------+----------------------+-------+----------------------+-------+
| ['n'] | ['n']                | ['n'] | ['n']                | ['w'] |
+-------+----------------------+-------+----------------------+-------+
| ['n'] | ['n']                | ['n'] | ['n']                | ['n'] |
+-------+----------------------+-------+----------------------+-------+
| ['n'] | ['n']                | ['n'] | ['n']                | ['n'] |
+-------+----------------------+-------+----------------------+-------+
| ['n'] | ['n']                | ['n'] | ['n']                | ['n'] |
+-------+----------------------+-------+----------------------+-------+
